

---

# ğŸ’³ Real-Time Payment Fraud Scoring System

A fully containerized, autonomous, real-time fraud detection pipeline built using Kafka, Machine Learning, MySQL, and Streamlit.

This system simulates live payment traffic, applies ML-based fraud scoring combined with rule-based velocity detection, persists results efficiently using batch operations, and exposes real-time operational monitoring via an analyst-oriented dashboard.

---

# ğŸ¯ Objectives

* Real-time transaction ingestion using Kafka
* Machine Learningâ€“based fraud probability scoring
* Rule-based behavioral fraud detection (velocity monitoring)
* High-performance batch persistence into MySQL
* Analyst-ready monitoring dashboard with export capabilities
* Fully containerized, reproducible deployment
* Autonomous startup with zero manual setup

---

# ğŸ— System Architecture

```
Docker Compose
â”‚
â”œâ”€â”€ Zookeeper
â”œâ”€â”€ Kafka
â”‚     â””â”€â”€ Topic: payments (auto-created)
â”‚
â”œâ”€â”€ MySQL (persistent Docker volume)
â”‚
â”œâ”€â”€ Producer (Dockerized)
â”‚     â””â”€â”€ Continuously generates simulated payment transactions
â”‚
â”œâ”€â”€ Consumer App (Dockerized)
â”‚     â”œâ”€â”€ Auto-trains ML model if not found
â”‚     â”œâ”€â”€ Applies ML fraud scoring
â”‚     â”œâ”€â”€ Applies velocity-based fraud rule
â”‚     â”œâ”€â”€ Classifies status (APPROVED / REVIEW / DECLINED)
â”‚     â”œâ”€â”€ Stores fraud reason (ML_MODEL / VELOCITY_RULE)
â”‚     â”œâ”€â”€ Batch inserts scored results
â”‚     â”œâ”€â”€ Handles Dead Letter Queue (DLQ)
â”‚     â””â”€â”€ Enforces idempotency via unique constraints
â”‚
â””â”€â”€ Streamlit Dashboard (Dockerized)
      â”œâ”€â”€ System health panel
      â”œâ”€â”€ Throughput monitoring
      â”œâ”€â”€ Fraud source breakdown
      â”œâ”€â”€ Velocity alert monitoring
      â”œâ”€â”€ High-risk transaction inspection
      â”œâ”€â”€ Customer investigation panel
      â””â”€â”€ CSV export for analysts
```

---

# âš™ï¸ Tech Stack

* Python 3.10
* Apache Kafka
* MySQL 8
* SQLAlchemy ORM
* Scikit-learn (RandomForestClassifier)
* Streamlit
* Docker & Docker Compose
* Pytest

---

# ğŸ“‚ Project Structure

```
app/
  config/
  database/
    connection.py
    models.py
    repository.py
  kafka/
  model/
  services/
    scoring_service.py
  main.py

scripts/
  sample_producer.py
  train_dummy_model.py

tests/
  test_predictor.py
  test_status_logic.py

dashboard.py
docker-compose.yml
Dockerfile
requirements.txt
```

---

# ğŸš€ Quick Start

Clone the repository and run:

```bash
docker compose up --build -d
```

Or to build and watch logs:
_i recommend using this to watch logs and when the app-1 logs transactions) appear it's time to open the UI_ 

```bash
docker compose up --build
```

Then open:

```
http://localhost:8501
```

No manual setup required:

* No Kafka topic creation
* No manual database schema creation
* No manual model training
* No local virtual environment


---

# ğŸ§  Autonomous Capabilities

At startup, the system automatically:

* Creates Kafka topic (`payments`)
* Waits for MySQL readiness
* Creates database schema if not present
* Trains ML model if missing
* Starts continuous transaction producer
* Starts fraud scoring consumer
* Applies batch insert optimization
* Launches monitoring dashboard
* Applies retry logic and DLQ handling

---

# ğŸ—„ Updated MySQL Schema

```sql
CREATE TABLE scored_transactions (
    id INT AUTO_INCREMENT PRIMARY KEY,
    transaction_id VARCHAR(100) NOT NULL UNIQUE,
    customer_id VARCHAR(100) NOT NULL,
    amount FLOAT,
    score FLOAT,
    prediction INT,
    status VARCHAR(20),
    reason VARCHAR(100),
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    processed_at DATETIME NULL,
    
    INDEX idx_customer_created (customer_id, created_at),
    INDEX idx_status (status)
);
```

### Schema Highlights

* `reason` â†’ explains fraud source (`ML_MODEL` / `VELOCITY_RULE`)
* Composite index `(customer_id, created_at)` â†’ optimized for velocity rule
* Indexed `status` â†’ fast dashboard aggregation
* Unique constraint on `transaction_id` â†’ idempotent processing

---

# ğŸ“Š Fraud Detection Logic

## 1ï¸âƒ£ Machine Learning Layer

* RandomForest classifier
* Outputs fraud probability score
* Threshold-based classification:

  * `>= 0.85` â†’ DECLINED
  * `>= 0.65` â†’ REVIEW
  * else â†’ APPROVED

---

## 2ï¸âƒ£ Velocity Rule Layer

* Counts transactions per customer over last 60 seconds
* Triggers when threshold exceeded (e.g., 12 tx / 60 sec)
* Slightly increases risk score
* Overrides classification when burst activity detected
* Sets `reason = VELOCITY_RULE`

This hybrid architecture balances predictive modeling with behavioral anomaly detection.

---

# ğŸ“ˆ Dashboard Features

## ğŸ”¹ System Health

* Lifetime status counters
* Transactions per minute
* Fraud rate monitoring
* Fraud spike alert detection

## ğŸ”¹ Fraud Intelligence

* Fraud source breakdown (ML vs Velocity)
* Velocity burst detection table
* High-risk transactions (time window configurable)
* Top risk customers (lifetime aggregation)

## ğŸ”¹ Customer Investigation

* Customer lifetime transaction count
* Fraud count
* Average risk score
* Full transaction history per customer

## ğŸ”¹ Analyst Export Features

Downloadable CSV exports:

* Fraud source breakdown
* Top risk customers
* High-risk transactions
* Velocity alerts
* Customer transactions
* âœ… Full dataset export (with optional row limit + status filter)

---

# âš¡ Performance Optimizations

* Indexed MySQL columns
* Composite index for velocity rule
* Batch inserts via `bulk_insert_mappings`
* Producer-side batching (`linger.ms`, `batch.num.messages`)
* Persistent MySQL Docker volume
* SQLAlchemy connection pooling (`pool_pre_ping`)
* TTL-based caching for lifetime metrics
* Idempotent transaction constraint
* Structured logging

---

# ğŸ”’ Reliability & Safety

* Dead Letter Queue (DLQ)
* Unique transaction ID constraint
* Pydantic schema validation
* Retry logic for database readiness
* Automatic ML training fallback
* Kafka consumer group coordination

---

# ğŸ§ª Running Tests

```bash
pytest
```

Expected output:

```
2 passed
```

Tests validate:

* ML predictor correctness
* Fraud status classification logic

---

# ğŸ“¦ Expected Deliverables 

This repository includes:

* Complete GitHub codebase
* Fully Dockerized reproducible environment
* README documentation with setup instructions
* Sample Kafka transaction generator
* MySQL schema definition
* Real-time ML fraud scoring implementation
* Monitoring dashboard
* CSV export capabilities
* Unit tests

---

# ğŸ System Summary

| Capability                     | Included |
| ------------------------------ | -------- |
| Fully Dockerized               | âœ…        |
| Autonomous Startup             | âœ…        |
| Real-Time Streaming Pipeline   | âœ…        |
| ML-Based Fraud Scoring         | âœ…        |
| Velocity-Based Fraud Detection | âœ…        |
| Fraud Source Attribution       | âœ…        |
| Persistent Database Storage    | âœ…        |
| Analyst CSV Exports            | âœ…        |
| Live Operational Monitoring    | âœ…        |
| Unit Testing                   | âœ…        |

---

# ğŸ‘¤ Author

Omar Khalil \
[omark8977@gmail.com](mailto:omark8977@gmail.com)

---

